{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  初识pandas\n",
    "两种数据结构：Series，DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n0    0\n1    1\n2    2\n3    3\n4    4\n5    5\n6    6\n7    7\n8    8\n9    9\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "#series是DataFrame的某一列或某几列\n",
    "#Series是一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成，即index和values两部分，\n",
    "#可以通过索引的方式选取Series中的单个或一组值。\n",
    "import numpy as np, pandas as pd\n",
    "#import pandas as pd\n",
    "\n",
    "arr1 = np.arange(10)\n",
    "s1 = pd.Series(arr1)\n",
    "print(arr1)\n",
    "print(s1)   #由于我们没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以指定索引：\n",
    "obj2 = pd.Series([4, 7, -5, 3], index=['a', 'b', 'c', 'd'])\n",
    "print(obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以用两种方式索引：\n",
    "print(obj2[0])\n",
    "print(obj2['a'])  # 都是该序列中的第一个元素。\n",
    "\n",
    "print(obj2[[1,3]])\n",
    "print(obj2[['b', 'd']])  # 打印第2、4个元素（注意两个方括号)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选和计算：\n",
    "print(obj2[obj2 > 3])\n",
    "print('-'*20)\n",
    "\n",
    "print(obj2**2)\n",
    "print('-'*20)\n",
    "\n",
    "print(np.exp(obj2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame是一个表格型的数据类型，每列值类型可以不同\n",
    "#pandas提供了很多不同格式数据的导入和导出方法，可以将其他格式数据转为DataFrame格式。\n",
    "#我们可以将list、dict格式数据转为dataFrame格式，也可以从本地的csv、xlsx、json等文本格式数据读取和保存数据等等。\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "df= pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 是基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。\n",
    "#首先需要在命令行打开python环境并且使用pip install pandas安装pandas库以及numpy.pandas安装会用到numpy库，因此在安装pandas之前一定要安装好numpy。\n",
    "import pandas as pd\n",
    "import numpy\n",
    "data = pd.read_csv('data/staff.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/students.xlsx',sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_excel(io, sheet_name=0, header=0, names=None, index_col=None)\n",
    "#一个需要注意的参数是sheet_name。这个参数是指定读取该excel中具体哪个表的数据，默认为0，即为第一个表。如果传入1，则为第2个表；可指定传入表名，如\"Sheet1\"；也可传入多个表，如[0,'Sheet3']，传入第一个表和名为'Sheet3'的表。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 可视化显示部分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('默认前五行'+'*'*10)\n",
    "print(data.head()) # 默认前五行\n",
    "\n",
    "print('默认前几行'+'*'*10)\n",
    "print(data.head(3))# 也可以指定默认前几行\n",
    "\n",
    "print('默认后五行'+'*'*10)\n",
    "print(data.tail()) #默认显示后五行\n",
    "\n",
    "print('指定显示某一行'+'*'*10)\n",
    "print(data.loc[1])\n",
    "\n",
    "\n",
    "print('指定显示某几行'+'*'*10)\n",
    "print(data.loc[1:3])\n",
    "print(data.loc[[1,3,5]])\n",
    "\n",
    "print('取出  指定行、指定列的值'+'*'*10) \n",
    "print(data.loc[1,\"name\"])\n",
    "\n",
    "print('取出指定列的值'+'*'*10)\n",
    "# 取出指定的列\n",
    "print(data[\"id\"].head())\n",
    "print(data[[\"id\",\"sex\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas有两个数据结构：Series和DataFrame。\n",
    "# 直接取出来的数据放入的是DataFrame\n",
    "print(type(data))\n",
    "\n",
    "# DataFrame的某几列--->成为Series\n",
    "print(type(data[\"name\"]))\n",
    "\n",
    "# DataFrame的某几行--->仍然是DataFrame\n",
    "print(type(data.loc[0:3]))\n",
    "\n",
    "# DataFrame的某几列的某几行--->成为Series\n",
    "print(type(data[\"name\"].loc[0:3]))\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切片\n",
    "print(data['hometown'])\n",
    "print(data[0:3])\n",
    "\n",
    "data.values  # df.values：将DataFrame转换为ndarray二维数组，注意后面不加()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas的groupby可以对dataframe数据类型分组,对满足相同的条件都放在同一组中\n",
    "group = data['hometown']\n",
    "print(group)\n",
    "for i in list(group):\n",
    "    print(i)\n",
    "#从print结果可见，转换后的list按照4种'year'生成了4个组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas的groupby可以对dataframe数据类型分组,对满足相同的条件都放在同一组中\n",
    "group = data.groupby('hometown')\n",
    "print(group)\n",
    "for i in list(group):\n",
    "    print(i)\n",
    "#从print结果可见，转换后的list按照4种'year'生成了4个组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多条件的分组\n",
    "group = data.groupby(['sex','hometown'])\n",
    "print(group)\n",
    "for i in list(group):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(np.ones((3,4))*0,columns=['a','b','c','d'])\n",
    "df2=pd.DataFrame(np.ones((3,4))*1,columns=['a','b','c','d'])\n",
    "df3=pd.DataFrame(np.ones((3,4))*2,columns=['a','b','c','d'])\n",
    "print(df1) #NaN\n",
    "res=pd.concat([df1,df2,df3],axis=0,ignore_index=True)#0表示竖项合并 1表示横项合并 ingnore_index重置序列index index变为0 1 2 3 4 5 6 7 8\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((3,4))*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join行相同的进行合并:相当于内连接\n",
    "res=pd.concat([df1,df2,df3],axis=1,join='outer')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用series创建Dataframe并导出\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, 5, 5, 2, 4.5, 2, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],}\n",
    "s_1 = pd.Series(data['animal'])\n",
    "s_2 = pd.Series(data['age'])\n",
    "s_3 = pd.Series(data['visits'])\n",
    "pd_1 = pd.DataFrame([s_1,s_2,s_3])\n",
    "pd_1.to_csv('pd_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 灵活的pandas索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('./data/流量练习数据.xls')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 基于位置的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们需要根据实际情况，填入对应的行参数和列参数。\n",
    "#选择一级流量来源渠道的所有行:第1行到第13行，对应行索引是0-12，但Python切片默认是含首不含尾的，要想选取0-12的索引行，我们得输入“0:13”，列想要全部选取，则输入冒号“：”即可。\n",
    "df.iloc[:13,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把所有渠道的流量来源和客单价单拎出来查看\n",
    "#所有流量渠道，也就是所有行，在第一个行参数的位置我们输入“：”；再看列，流量来源是第1列，客单价是第5列，对应的列索引分别是0和4：\n",
    "df.iloc[:,[0,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取二级、三级流量来源、来源明细对应的访客和转化\n",
    "df.iloc[13:18,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 基于条件的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断返回的结果\n",
    "df['流量来源'] == '一级'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择一级流量渠道的所有行\n",
    "df.loc[df['流量来源'] == '一级',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有渠道的流量来源和客单价单拎出来看一看\n",
    "df.loc[:,['流量来源','客单价']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取二级、三级流量来源、来源明细对应的访客和转化。\n",
    "df.loc[df['流量来源'].isin(['二级','三级']),['流量来源','来源明细','访客数','支付转化率']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 列的聚合函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())\n",
    "# 默认统计数值型数据每列数据平均值，标准差，最大值，最小值，25%，50%，75%比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['访客数'].mean()    #计算均值\n",
    "df['访客数'].std()     #计算标准差\n",
    "df['访客数'].median()  #计算中位数\n",
    "df['访客数'].max()     #计算最大值\n",
    "df['访客数'].min()     #计算最小值\n",
    "\n",
    "print('访客数均值：',df['访客数'].mean())\n",
    "print('转化率均值：',df['支付转化率'].mean())\n",
    "print('客单价均值：',df['客单价'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于流量渠道的数据，我们真正感兴趣的是优质渠道，有哪些渠道的访客数、转化率、客单价都高于平均值呢？他的销售占比又是怎么样的呢？\n",
    "count=0\n",
    "group = df['访客数'] > df['访客数'].mean()\n",
    "print(group)\n",
    "for i in list(group):\n",
    "    if i:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断是否同时大于均值\n",
    "(df['访客数'] > df['访客数'].mean()) & (df['支付转化率'] > df['支付转化率'].mean()) & (df['客单价'] > df['客单价'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于判断结果，筛选出我们希望的优质渠道\n",
    "df.loc[(df['访客数'] > df['访客数'].mean()) & \n",
    "      (df['支付转化率'] > df['支付转化率'].mean()) & \n",
    "      (df['客单价'] > df['客单价'].mean()),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 利用pandas清洗数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel('./data/清洗数据集.xlsx',sheet_name =  '一级流量')\n",
    "print(d1.head())\n",
    "d2 = pd.read_excel('./data/清洗数据集.xlsx',sheet_name =  '二级流量')\n",
    "print(d2.head())\n",
    "d3 = pd.read_excel('./data/清洗数据集.xlsx',sheet_name =  '三级流量')\n",
    "print(d3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#横向合并\n",
    "df = pd.concat([d1,d2,d3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#横向合并\n",
    "h1 = pd.DataFrame({'语文':[93,80,85,76,58],'数学':[87,99,95,85,70],'英语':[80,85,97,65,88]},\n",
    "                 index = ['韩梅梅','李雷','李华','王明','铁蛋'])\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = pd.DataFrame({'篮球':[93,80,85,76],'舞蹈':[87,99,95,85]},\n",
    "                 index = ['李华','王明','铁蛋','刘强'])\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = h1,right = h2,left_index = True,right_index = True,how = 'inner')\n",
    "#left_index与right_index是当我们用索引（这两个表的名字在索引中）连接时指定的参数，设置为on表示用该表的索引作为连接的条件（或者说桥梁）。\n",
    "#how是指定连接方式，这里用的inner，表示我们基于姓名索引来匹配，只返回两个表中共同（同时出现）姓名的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = h1,right = h2,left_index = True,right_index = True,how = 'left')\n",
    "#左连接（left）和右连接（right），我们可以直观理解为哪边的表是老大，谁是老大，就听谁的（所有行全部保持），先看左连接，左表h1原封不动，右边根据左表进行合并，如果存在相关的名字，就正常返回数据，如果不存在（韩梅梅、李雷），就返回空(NAN)值；右连接就是听右表的，左表有则返回无则为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = h1,right = h2,left_index = True,right_index = True,how = 'outer')\n",
    "#外连接是两张表妥协的产物，我的数据全保留，你的也全保留，你有我无的就空着，你无我有的也空着。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除有空值的行\n",
    "df.dropna(axis=0)\n",
    "\n",
    "# 可以根据需求，去掉在某些列（subset=）上为空的数据的行.即指定列的某一行数据为空时，该行才会被删除\n",
    "df.dropna(subset = ['支付金额'])\n",
    "\n",
    "# 可以根据需求去掉某些存在空数据的 某些列\n",
    "print(df.dropna(axis=1))\n",
    "\n",
    "\n",
    "#可以填充缺失数据：fillna()函数，inplace参数控制返回新对象还是就地修改\n",
    "print(df.fillna(0, inplace = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去重\n",
    "repeat = pd.concat([df,df])\n",
    "print('重复的数据集一共多少行：',len(repeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = repeat.drop_duplicates()\n",
    "print('去重后的数据集一共多少行：',len(unique))\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除指定列重复的数据\n",
    "df.drop_duplicates(subset = '流量级别')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep值等于last，保留最后一行数据，不输入keep值时，系统默认会给keep赋值为first，就会保留第一行数据而删掉其他的。\n",
    "df.drop_duplicates(subset = '流量级别',keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除一行并写入到原csv文件\n",
    "data_new=df.drop(0,axis=0)\n",
    "data_new.to_csv('./data/new_test.csv',encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按条件查看/筛选\n",
    "#筛选出访客数大于10000的渠道\n",
    "df.loc[(df['访客数'] > 10000) & (df['流量级别'] == '一级'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序：sort_values函数，顾名思义是按照数值进行排序，首先要传入的参数是列参数，即我们根据哪一列的数值来进行排序，ascending参数决定了排序顺序，等于Flase则是从大到小的降序，设置为True则是升序。\n",
    "sort_df = df.sort_values('支付金额',ascending = False)\n",
    "sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#无论是删空的dropna，还是去重的drop_duplicates，或者是排序的sort_values，在对源数据进行操作后，源数据并未改变，这是因为我们没有对这几个函数的inplace值进行设置，如果设置成inplace = True，删空、去重和排序都会在源数据上生效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('流量级别')['访客数','支付金额'].sum()\n",
    "#sum代表我们先按照流量级别进行分组，再对分组内的字段求和。由于没有指定求和的列，所以是对所有数值型字段进行了求和。此处我们只想要各级别流量下的访客数和支付金额，需要指明参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#流量级别作为汇总的依据列，默认转化为索引列，如果我们不希望它变成索引，向groupby内传入参数as_index = False\n",
    "df.groupby('流量级别',as_index = False)['访客数','支付金额'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分：cut函数。我们想对流量级别进行百、千、万的归类，所以把分组数值标准传入bins参数。\n",
    "pd.cut(x = df['访客数'],bins = [0,100,1000,10000,100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可以看到，在不设置right的情况下，分组区间是默认左开右闭的，而我们希望的是左闭右开，即百级流量渠道访客数在0-99之间，所以需要将right值设置为False。\n",
    "df['分类打标'] = pd.cut(x = df['访客数'],bins = [0,100,1000,10000,100000],\n",
    "                    right = False,labels = ['辣鸡','百级','千级','万级'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习题：给学生三次测试的成绩表，统计每个学生三次成绩的总和及平均分，并添加到最后两列；统计每次测试成绩、学生总分、平均分的平均分，并添加到最后一行\n",
    "import pandas as pd\n",
    "\n",
    "students = pd.read_excel('./data/students.xlsx', index_col='ID')\n",
    "\n",
    "row_sum = students[['Test_1', 'Test_2', 'Test_3']].sum(axis=1)\n",
    "row_mean = students[['Test_1', 'Test_2', 'Test_3']].mean(axis=1)\n",
    "\n",
    "students['Total'] = row_sum\n",
    "students['Average'] = row_mean\n",
    "print(students)\n",
    "\n",
    "col_mean = students[['Test_1', 'Test_2', 'Test_3', 'Total', 'Average']].mean()\n",
    "col_mean['Name'] = 'Summary'\n",
    "students = students.append(col_mean, ignore_index=True)\n",
    "print(students)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.3 64-bit ('anaconda3': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}